# æ¶æ„å¯è¡Œæ€§è¯„ä¼°ä¸å®æ–½å»ºè®®

## æ‰§è¡Œæ‘˜è¦

**ç»“è®º**: âœ… ä½¿ç”¨ Redpanda Connect å¤„ç†åœ°é“ç©ºè°ƒæ•°æ®å¹¶å­˜å…¥ TimescaleDB çš„æ–¹æ¡ˆ **å®Œå…¨å¯è¡Œ**,ä¸”å…·æœ‰è‰¯å¥½çš„æŠ€æœ¯ä¼˜åŠ¿ã€‚

**å…³é”®å‘ç°**:
- Redpanda Connect æ”¯æŒå¤šç§äºŒè¿›åˆ¶æ•°æ®å¤„ç†æ–¹å¼
- TimescaleDB å®Œç¾æ”¯æŒæ—¶åºæ•°æ®åœºæ™¯
- æ¶æ„ç®€æ´ã€å¯ç»´æŠ¤æ€§é«˜
- å¯ä»¥åœ¨ç®¡é“ä¸­å®ç°åŸºç¡€æ•…éšœæ£€æµ‹
- ä¸ºæ•…éšœé¢„æµ‹æä¾›è‰¯å¥½çš„æ•°æ®åŸºç¡€

## æ•´ä½“æ¶æ„æ–¹æ¡ˆ

### æ¨èæ¶æ„

```mermaid
graph TB
    subgraph "è¾¹ç¼˜é‡‡é›†å±‚"
        A1[è½¦å¢1ç©ºè°ƒ] --> B[è¾¹ç¼˜ç½‘å…³]
        A2[è½¦å¢2ç©ºè°ƒ] --> B
        A3[è½¦å¢Nç©ºè°ƒ] --> B
        B --> C[äºŒè¿›åˆ¶æ•°æ®æ–‡ä»¶]
    end
    
    subgraph "æ•°æ®è½¬æ¢å±‚"
        C --> D[è½¬æ¢æœåŠ¡<br/>Python/Go]
        D --> E[Avro Schema]
        E --> F[Redpanda Cluster]
        F --> G[Schema Registry]
    end
    
    subgraph "æµå¤„ç†å±‚"
        F --> H1[Redpanda Connect å®ä¾‹1<br/>æ•°æ®è§£æ+æ¸…æ´—]
        F --> H2[Redpanda Connect å®ä¾‹2<br/>æ•°æ®è§£æ+æ¸…æ´—]
        F --> H3[Redpanda Connect å®ä¾‹N<br/>æ•°æ®è§£æ+æ¸…æ´—]
        
        H1 --> I[å®æ—¶æ•…éšœæ£€æµ‹]
        H2 --> I
        H3 --> I
    end
    
    subgraph "å­˜å‚¨å±‚"
        I --> J[TimescaleDB<br/>Hypertable]
        J --> K1[åŸå§‹æ•°æ®è¡¨]
        J --> K2[1å°æ—¶èšåˆ]
        J --> K3[1å¤©èšåˆ]
    end
    
    subgraph "åº”ç”¨å±‚"
        K1 --> L1[Grafana<br/>å®æ—¶ç›‘æ§]
        K2 --> L1
        K3 --> L1
        
        K1 --> L2[æ•…éšœé¢„æµ‹æ¨¡å‹<br/>ML Pipeline]
        K2 --> L2
        K3 --> L2
        
        K1 --> L3[å‘Šè­¦ç³»ç»Ÿ]
    end
```

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| æ¶ˆæ¯é˜Ÿåˆ— | Redpanda | Kafka å…¼å®¹,æ›´é«˜æ€§èƒ½ |
| Schema ç®¡ç† | Schema Registry | Avro schema ç‰ˆæœ¬ç®¡ç† |
| æµå¤„ç† | Redpanda Connect | è½»é‡çº§,æ˜“äºé…ç½® |
| æ—¶åºæ•°æ®åº“ | TimescaleDB | PostgreSQL æ‰©å±• |
| å¯è§†åŒ– | Grafana | å¼€æºç›‘æ§é¢æ¿ |
| æ•…éšœé¢„æµ‹ | Python ML | scikit-learn/TensorFlow |

## è¯¦ç»†æ–¹æ¡ˆè®¾è®¡

### é˜¶æ®µ 1: æ•°æ®é‡‡é›†å’Œè½¬æ¢

#### 1.1 è¾¹ç¼˜é‡‡é›†

```python
# è¾¹ç¼˜ç½‘å…³ä¼ªä»£ç 
import struct
import time
from pathlib import Path

class HVACDataCollector:
    def collect_binary_data(self, device_id, sensors):
        """é‡‡é›†ä¼ æ„Ÿå™¨æ•°æ®å¹¶å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶"""
        data = struct.pack(
            '<16sQI100f',  # æ ¼å¼: è®¾å¤‡ID(16å­—èŠ‚), æ—¶é—´æˆ³(8å­—èŠ‚), è½¦å¢å·(4å­—èŠ‚), 100ä¸ªfloat
            device_id.encode('utf-8').ljust(16),
            int(time.time() * 1000),
            sensors['car_number'],
            *[sensors.get(f'field_{i}', 0.0) for i in range(100)]
        )
        
        # å†™å…¥æ–‡ä»¶
        filename = Path(f'/data/hvac_{device_id}_{timestamp}.bin')
        filename.write_bytes(data)
        
        return filename
```

#### 1.2 è½¬æ¢æœåŠ¡

```python
# è½¬æ¢æœåŠ¡: äºŒè¿›åˆ¶ -> Avro -> Redpanda
import struct
from confluent_kafka import SerializingProducer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroSerializer
from confluent_kafka.serialization import StringSerializer
import glob
import os

class BinaryToAvroConverter:
    def __init__(self, schema_registry_url, kafka_bootstrap_servers):
        self.schema_registry_client = SchemaRegistryClient({
            'url': schema_registry_url
        })
        
        # åŠ è½½ Avro Schema
        with open('hvac_schema.avsc', 'r') as f:
            schema_str = f.read()
        
        avro_serializer = AvroSerializer(
            self.schema_registry_client,
            schema_str
        )
        
        self.producer = SerializingProducer({
            'bootstrap.servers': kafka_bootstrap_servers,
            'key.serializer': StringSerializer('utf_8'),
            'value.serializer': avro_serializer
        })
    
    def parse_binary_file(self, filepath):
        """è§£æäºŒè¿›åˆ¶æ–‡ä»¶"""
        with open(filepath, 'rb') as f:
            data = f.read()
        
        # è§£æå›ºå®šæ ¼å¼
        device_id = data[0:16].decode('utf-8').strip('\x00')
        timestamp = struct.unpack('<Q', data[16:24])[0]
        car_number = struct.unpack('<I', data[24:28])[0]
        
        # è§£æ100ä¸ªå­—æ®µ
        offset = 28
        fields = struct.unpack('<100f', data[offset:offset+400])
        
        return {
            'device_id': device_id,
            'timestamp': timestamp,
            'car_number': car_number,
            'temp_supply_air': fields[0],
            'temp_return_air': fields[1],
            'pressure_compressor': fields[2],
            # ... æ˜ å°„æ‰€æœ‰å­—æ®µ
        }
    
    def process_files(self, data_dir):
        """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰äºŒè¿›åˆ¶æ–‡ä»¶"""
        for filepath in glob.glob(f'{data_dir}/*.bin'):
            try:
                record = self.parse_binary_file(filepath)
                
                # å‘é€åˆ° Redpanda
                self.producer.produce(
                    topic='hvac-raw-data',
                    key=record['device_id'],
                    value=record,
                    on_delivery=self.delivery_report
                )
                
                # æˆåŠŸååˆ é™¤æ–‡ä»¶
                os.remove(filepath)
                
            except Exception as e:
                print(f'Error processing {filepath}: {e}')
                # ç§»åŠ¨åˆ°é”™è¯¯ç›®å½•
                os.rename(filepath, f'/data/errors/{os.path.basename(filepath)}')
        
        self.producer.flush()
    
    def delivery_report(self, err, msg):
        if err:
            print(f'Delivery failed: {err}')
        else:
            print(f'Message delivered to {msg.topic()} [{msg.partition()}]')

# è¿è¡Œè½¬æ¢æœåŠ¡
converter = BinaryToAvroConverter(
    schema_registry_url='http://schema-registry:8081',
    kafka_bootstrap_servers='redpanda:9092'
)

# å®šæœŸæ‰«æå¹¶å¤„ç†æ–‡ä»¶
import schedule
schedule.every(10).seconds.do(lambda: converter.process_files('/data/incoming'))

while True:
    schedule.run_pending()
    time.sleep(1)
```

### é˜¶æ®µ 2: æµå¤„ç†å’Œæ•…éšœæ£€æµ‹

#### 2.1 Redpanda Connect é…ç½®

å‚è§ `03-timescaledb-integration.md` ä¸­çš„å®Œæ•´é…ç½®ã€‚

#### 2.2 æ•…éšœæ£€æµ‹è§„åˆ™å¼•æ“

```yaml
# åœ¨ Redpanda Connect ä¸­å®ç°è§„åˆ™å¼•æ“
pipeline:
  processors:
    - mapping: |
        # å®šä¹‰æ•…éšœæ£€æµ‹è§„åˆ™
        root = this
        
        # è§„åˆ™1: æ¸©åº¦å¼‚å¸¸
        let temp_too_high = this.temp_supply_air > 35
        let temp_too_low = this.temp_supply_air < 10
        let temp_abnormal = $temp_too_high || $temp_too_low
        
        # è§„åˆ™2: å‹ç¼©æœºå¼‚å¸¸
        let pressure_abnormal = this.pressure_compressor > 2000 || this.pressure_compressor < 500
        let current_abnormal = this.current_compressor > 50 || this.current_compressor < 5
        
        # è§„åˆ™3: æ¸©å·®å¼‚å¸¸
        let temp_diff = this.temp_supply_air - this.temp_return_air
        let temp_diff_abnormal = $temp_diff < 3 || $temp_diff > 15
        
        # è§„åˆ™4: é¢‘ç¹å¯åœ (éœ€è¦çŠ¶æ€)
        # è¿™ä¸ªéœ€è¦æ›´å¤æ‚çš„é€»è¾‘,å¯ä»¥åœ¨åç»­çš„ ML æ¨¡å‹ä¸­å¤„ç†
        
        # ç»¼åˆåˆ¤æ–­
        root.fault_detected = $temp_abnormal || $pressure_abnormal || $current_abnormal || $temp_diff_abnormal
        
        root.fault_reasons = []
        root.fault_reasons = if $temp_too_high { $fault_reasons.append("HIGH_TEMP") } else { $fault_reasons }
        root.fault_reasons = if $temp_too_low { $fault_reasons.append("LOW_TEMP") } else { $fault_reasons }
        root.fault_reasons = if $pressure_abnormal { $fault_reasons.append("ABNORMAL_PRESSURE") } else { $fault_reasons }
        root.fault_reasons = if $current_abnormal { $fault_reasons.append("ABNORMAL_CURRENT") } else { $fault_reasons }
        root.fault_reasons = if $temp_diff_abnormal { $fault_reasons.append("ABNORMAL_TEMP_DIFF") } else { $fault_reasons }
        
        # è®¾ç½®å‘Šè­¦çº§åˆ«
        root.alert_level = if this.fault_code != 0 {
          "critical"
        } else if this.fault_detected {
          "warning"
        } else {
          "normal"
        }
```

### é˜¶æ®µ 3: æ•…éšœé¢„æµ‹

#### 3.1 æ•°æ®æå–

```python
# ä» TimescaleDB æå–è®­ç»ƒæ•°æ®
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('postgresql://user:pass@timescaledb:5432/metro_hvac')

query = """
SELECT 
    device_id,
    time,
    temp_supply_air,
    temp_return_air,
    pressure_compressor,
    current_compressor,
    power_total,
    temp_diff,
    -- æ»åç‰¹å¾ (å‰1å°æ—¶çš„å¹³å‡å€¼)
    AVG(temp_supply_air) OVER (
        PARTITION BY device_id 
        ORDER BY time 
        RANGE BETWEEN INTERVAL '1 hour' PRECEDING AND CURRENT ROW
    ) AS temp_1h_avg,
    -- è¶‹åŠ¿ç‰¹å¾
    temp_supply_air - LAG(temp_supply_air, 12) OVER (
        PARTITION BY device_id ORDER BY time
    ) AS temp_1h_change,  -- å‡è®¾æ¯5åˆ†é’Ÿä¸€æ¡æ•°æ®
    -- ç›®æ ‡å˜é‡: æœªæ¥2å°æ—¶æ˜¯å¦å‘ç”Ÿæ•…éšœ
    LEAD(fault_code, 24) OVER (
        PARTITION BY device_id ORDER BY time
    ) != 0 AS fault_next_2h
FROM hvac_measurements
WHERE time > NOW() - INTERVAL '90 days'
  AND data_quality > 0.8
ORDER BY device_id, time
"""

df = pd.read_sql(query, engine)
```

#### 3.2 ç‰¹å¾å·¥ç¨‹

```python
from sklearn.preprocessing import StandardScaler
import numpy as np

# åˆ›å»ºæ›´å¤šç‰¹å¾
df['temp_diff'] = df['temp_supply_air'] - df['temp_return_air']
df['power_efficiency'] = df['power_total'] / (df['temp_diff'] + 1)  # é¿å…é™¤é›¶

# rolling ç‰¹å¾
df['temp_rolling_std'] = df.groupby('device_id')['temp_supply_air'].transform(
    lambda x: x.rolling(window=12, min_periods=1).std()
)

# æ—¶é—´ç‰¹å¾  
df['hour'] = df['time'].dt.hour
df['day_of_week'] = df['time'].dt.dayofweek
df['is_summer'] = df['time'].dt.month.isin([6, 7, 8]).astype(int)

# æ ‡å‡†åŒ–
scaler = StandardScaler()
feature_cols = [
    'temp_supply_air', 'temp_return_air', 'pressure_compressor',
    'current_compressor', 'power_total', 'temp_diff', 
    'temp_1h_avg', 'temp_1h_change', 'temp_rolling_std'
]
df[feature_cols] = scaler.fit_transform(df[feature_cols])
```

#### 3.3 æ¨¡å‹è®­ç»ƒ

```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, roc_auc_score

# å‡†å¤‡æ•°æ®
X = df[feature_cols + ['hour', 'day_of_week', 'is_summer']]
y = df['fault_next_2h']

# åˆ é™¤åŒ…å« NaN çš„è¡Œ
mask = ~(X.isna().any(axis=1) | y.isna())
X = X[mask]
y = y[mask]

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# è®­ç»ƒæ¨¡å‹
model = GradientBoostingClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=42
)

model.fit(X_train, y_train)

# è¯„ä¼°
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

print(classification_report(y_test, y_pred))
print(f'AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}')

# ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance)
```

#### 3.4 æ¨¡å‹éƒ¨ç½²

```python
# ä¿å­˜æ¨¡å‹
import joblib
joblib.dump(model, 'hvac_fault_prediction_model.pkl')
joblib.dump(scaler, 'hvac_scaler.pkl')

# åˆ›å»ºé¢„æµ‹æœåŠ¡
from flask import Flask, request, jsonify

app = Flask(__name__)

model = joblib.load('hvac_fault_prediction_model.pkl')
scaler = joblib.load('hvac_scaler.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    
    # ä» TimescaleDB æå–æœ€æ–°æ•°æ®å¹¶æ„å»ºç‰¹å¾
    # ... (æŸ¥è¯¢é€»è¾‘)
    
    # é¢„æµ‹
    features = [...]  # æå–çš„ç‰¹å¾
    prediction_proba = model.predict_proba([features])[0][1]
    
    return jsonify({
        'device_id': data['device_id'],
        'fault_probability': float(prediction_proba),
        'prediction': 'high_risk' if prediction_proba > 0.7 else 'normal',
        'timestamp': time.time()
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## éƒ¨ç½²æ¶æ„

### å®¹å™¨åŒ–éƒ¨ç½² (æ¨è)

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Redpanda (Kafka å…¼å®¹)
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    command:
      - redpanda start
      - --smp 2
      - --memory 2G
      - --advertise-kafka-addr redpanda:9092
    ports:
      - "9092:9092"
      - "9644:9644"  # Admin API
    volumes:
      - redpanda-data:/var/lib/redpanda/data

  # Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    depends_on:
      - redpanda
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: redpanda:9092
    ports:
      - "8081:8081"

  # TimescaleDB
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    environment:
      POSTGRES_USER: hvac_user
      POSTGRES_PASSWORD: secure_password
      POSTGRES_DB: metro_hvac
    ports:
      - "5432:5432"
    volumes:
      - timescale-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  # Redpanda Connect (å¤šå®ä¾‹)
  connect-1:
    image: docker.redpanda.com/redpandadata/connect:latest
    depends_on:
      - redpanda
      - timescaledb
      - schema-registry
    volumes:
      - ./connect-config.yaml:/connect.yaml
    command: run /connect.yaml
    environment:
      - INSTANCE_ID=1

  connect-2:
    image: docker.redpanda.com/redpandadata/connect:latest
    depends_on:
      - redpanda
      - timescaledb
      - schema-registry
    volumes:
      - ./connect-config.yaml:/connect.yaml
    command: run /connect.yaml
    environment:
      - INSTANCE_ID=2

  # è½¬æ¢æœåŠ¡
  converter:
    build: ./converter
    depends_on:
      - redpanda
      - schema-registry
    volumes:
      - /data/incoming:/data/incoming
      - /data/errors:/data/errors
    environment:
      KAFKA_BOOTSTRAP_SERVERS: redpanda:9092
      SCHEMA_REGISTRY_URL: http://schema-registry:8081

  # Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    depends_on:
      - timescaledb
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin

volumes:
  redpanda-data:
  timescale-data:
  grafana-data:
```

## å¯è¡Œæ€§è¯„ä¼°

### âœ… æŠ€æœ¯å¯è¡Œæ€§

| éœ€æ±‚ | è¯„ä¼° | è¯´æ˜ |
|------|------|------|
| äºŒè¿›åˆ¶æ•°æ®å¤„ç† | âœ… å¯è¡Œ | é€šè¿‡è½¬æ¢æœåŠ¡è½¬ä¸º Avro æ ¼å¼ |
| 100+ å­—æ®µå­˜å‚¨ | âœ… å¯è¡Œ | TimescaleDB æ”¯æŒå®½è¡¨ |
| å®æ—¶å¤„ç† | âœ… å¯è¡Œ | Redpanda Connect ä½å»¶è¿Ÿ |  
| æ•…éšœæ£€æµ‹ | âœ… å¯è¡Œ | Bloblang è§„åˆ™å¼•æ“ |
| æ•…éšœé¢„æµ‹ | âœ… å¯è¡Œ | ML æ¨¡å‹åŸºäºå†å²æ•°æ®è®­ç»ƒ |
| æ•°æ®å±•ç¤º | âœ… å¯è¡Œ | Grafana + TimescaleDB |
| æ°´å¹³æ‰©å±• | âœ… å¯è¡Œ | æ‰€æœ‰ç»„ä»¶æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½² |

### ğŸ’¡ æ€§èƒ½è¯„ä¼°

**æ•°æ®è§„æ¨¡å‡è®¾**:
- è½¦å¢æ•°: 500 ä¸ªè®¾å¤‡
- é‡‡æ ·é¢‘ç‡: æ¯ 5 åˆ†é’Ÿ
- æ•°æ®é‡: ~100 KB/æ¡ (100å­—æ®µ)

**ååé‡è®¡ç®—**:
```
æ¯ç§’æ¶ˆæ¯æ•° = 500 è®¾å¤‡ / (5 * 60 ç§’) = 1.67 msg/s
æ¯ç§’æ•°æ®é‡ = 1.67 * 100 KB â‰ˆ 167 KB/s
æ¯å¤©æ•°æ®é‡ = 167 KB/s * 86400 s â‰ˆ 14 GB/å¤©
æ¯å¹´æ•°æ®é‡ â‰ˆ 5 TB/å¹´ (å‹ç¼©åçº¦ 1-2 TB)
```

**æ€§èƒ½ç»“è®º**:
- âœ… Redpanda: è½»æ¾å¤„ç† 1.67 msg/s (æ”¯æŒ 100K+ msg/s)
- âœ… Redpanda Connect: è½»æ¾å¤„ç† (æ”¯æŒ 10K+ msg/s)
- âœ… TimescaleDB: è½»æ¾å¤„ç† (æ‰¹é‡å†™å…¥æ”¯æŒ 100K+ rows/s)

### ğŸ’° æˆæœ¬è¯„ä¼°

| ç»„ä»¶ | æ¨èé…ç½® | å¹´æˆæœ¬ä¼°ç®— (äº‘) |
|------|---------|---------------|
| Redpanda | 3 èŠ‚ç‚¹,4C8G | ~$3,000 |
| TimescaleDB | 1 ä¸» + 1 å¤‡,8C16G | ~$5,000 |
| Redpanda Connect | 2 å®ä¾‹,2C4G | ~$1,000 |
| è½¬æ¢æœåŠ¡ | 2 å®ä¾‹,2C4G | ~$1,000 |
| Grafana | 1 å®ä¾‹,2C4G | ~$500 |
| **æ€»è®¡** | | **~$10,500/å¹´** |

è‡ªå»ºæˆæœ¬ä¼šæ›´ä½ (çº¦ 30-50%)ã€‚

### â±ï¸ å®æ–½å‘¨æœŸ

| é˜¶æ®µ | å·¥ä½œå†…å®¹ | é¢„è®¡æ—¶é—´ |
|------|---------|---------|
| 1 | ç¯å¢ƒæ­å»ºå’Œæµ‹è¯• | 1 å‘¨ |
| 2 | è½¬æ¢æœåŠ¡å¼€å‘ | 2 å‘¨ |
| 3 | Redpanda Connect é…ç½® | 1 å‘¨ |
| 4 | TimescaleDB è¡¨è®¾è®¡å’Œä¼˜åŒ– | 1 å‘¨ |
| 5 | ç›‘æ§é¢æ¿å¼€å‘ | 1 å‘¨ |
| 6 | æ•…éšœæ£€æµ‹è§„åˆ™å¼€å‘ | 1 å‘¨ |
| 7 | é›†æˆæµ‹è¯• | 2 å‘¨ |
| 8 | è¯•è¿è¡Œå’Œè°ƒä¼˜ | 2 å‘¨ |
| **æ€»è®¡** | | **~11 å‘¨ (2.5ä¸ªæœˆ)** |

æ•…éšœé¢„æµ‹æ¨¡å‹å¯ä»¥åœ¨åæœŸè¿­ä»£ä¸­é€æ­¥å®Œå–„ã€‚

## é£é™©å’ŒæŒ‘æˆ˜

### âš ï¸ æ½œåœ¨é£é™©

1. **æ•°æ®è´¨é‡**
   - é£é™©: äºŒè¿›åˆ¶æ ¼å¼å˜æ›´å¯¼è‡´è§£æå¤±è´¥
   - ç¼“è§£: Schema Registry ç‰ˆæœ¬ç®¡ç† + ä¸¥æ ¼çš„æ•°æ®éªŒè¯

2. **æ•°æ®å»¶è¿Ÿ**
   - é£é™©: æ–‡ä»¶ä¼ è¾“å»¶è¿Ÿ
   - ç¼“è§£: ä¼˜åŒ–æ–‡ä»¶ä¼ è¾“ç­–ç•¥,è€ƒè™‘å®æ—¶æµå¼ä¼ è¾“

3. **å­˜å‚¨æˆæœ¬**  
   - é£é™©: å†å²æ•°æ®é‡å¤§
   - ç¼“è§£: TimescaleDB å‹ç¼©ç­–ç•¥ + æ•°æ®ä¿ç•™ç­–ç•¥

4. **ç³»ç»Ÿå¯ç”¨æ€§**
   - é£é™©: å•ç‚¹æ•…éšœ
   - ç¼“è§£: æ‰€æœ‰ç»„ä»¶éƒ¨ç½²é«˜å¯ç”¨é›†ç¾¤

### ğŸ”§ æŠ€æœ¯æŒ‘æˆ˜

1. **å¤æ‚äºŒè¿›åˆ¶æ ¼å¼è§£æ**
   - æŒ‘æˆ˜: 100+ å­—æ®µçš„è§£æé€»è¾‘å¤æ‚
   - è§£å†³: è¯¦ç»†çš„æ•°æ®å­—å…¸æ–‡æ¡£ + å•å…ƒæµ‹è¯•

2. **æ•…éšœé¢„æµ‹æ¨¡å‹å‡†ç¡®æ€§**
   - æŒ‘æˆ˜: éœ€è¦å¤§é‡å†å²æ•…éšœæ•°æ®è®­ç»ƒ
   - è§£å†³: å…ˆä»ç®€å•è§„åˆ™å¼•æ“å¼€å§‹,é€æ­¥ç§¯ç´¯æ•°æ®è®­ç»ƒ ML æ¨¡å‹

3. **å®æ—¶æ€§è¦æ±‚**
   - æŒ‘æˆ˜: å‘Šè­¦éœ€è¦åŠæ—¶
   - è§£å†³: ä¼˜åŒ–æ‰¹å¤„ç†å‚æ•°,å¹³è¡¡ååé‡å’Œå»¶è¿Ÿ

## æ€»ç»“å’Œå»ºè®®

### âœ… æ•´ä½“ç»“è®º

ä½¿ç”¨ **Redpanda Connect + TimescaleDB** æ–¹æ¡ˆå¤„ç†åœ°é“ç©ºè°ƒæ•°æ® **å®Œå…¨å¯è¡Œ**,ä¸”å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿:

1. **æ¶æ„ç®€æ´**: ç»„ä»¶å°‘,æ˜“äºç»´æŠ¤
2. **æŠ€æœ¯æˆç†Ÿ**: æ‰€æœ‰ç»„ä»¶ç”Ÿäº§çº§åˆ«
3. **æ€§èƒ½ä¼˜ç§€**: æ»¡è¶³å®æ—¶æ€§å’Œååé‡è¦æ±‚
4. **æˆæœ¬å¯æ§**: ç›¸æ¯”å¤§æ•°æ®å¹³å°æˆæœ¬ä½
5. **æ˜“äºæ‰©å±•**: æ”¯æŒæ°´å¹³æ‰©å±•

### ğŸ¯ å®æ–½å»ºè®®

#### çŸ­æœŸ (1-3ä¸ªæœˆ)

1. **POC éªŒè¯**
   - æ­å»ºå•æœºæµ‹è¯•ç¯å¢ƒ
   - éªŒè¯äºŒè¿›åˆ¶æ•°æ®è§£æé€»è¾‘
   - æµ‹è¯•ç«¯åˆ°ç«¯æ•°æ®æµ

2. **æ ¸å¿ƒåŠŸèƒ½å¼€å‘**
   - è½¬æ¢æœåŠ¡å¼€å‘å’Œæµ‹è¯•
   - Redpanda Connect é…ç½®
   - TimescaleDB è¡¨ç»“æ„è®¾è®¡
   - åŸºç¡€ç›‘æ§é¢æ¿

3. **è¯•è¿è¡Œ**
   - å°‘é‡è®¾å¤‡æ¥å…¥
   - æ•°æ®è´¨é‡ç›‘æ§
   - æ€§èƒ½è°ƒä¼˜

#### ä¸­æœŸ (3-6ä¸ªæœˆ)

1. **å…¨é‡éƒ¨ç½²**
   - æ‰€æœ‰è®¾å¤‡æ¥å…¥
   - é«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²
   - å®Œå–„ç›‘æ§å‘Šè­¦

2. **åŸºç¡€æ•…éšœæ£€æµ‹**
   - è§„åˆ™å¼•æ“å¼€å‘
   - å‘Šè­¦æ¨é€é›†æˆ
   - è¿ç»´å›¢é˜ŸåŸ¹è®­

#### é•¿æœŸ (6-12ä¸ªæœˆ)

1. **æ•…éšœé¢„æµ‹æ¨¡å‹**
   - ç§¯ç´¯å†å²æ•…éšœæ•°æ®
   - ç‰¹å¾å·¥ç¨‹è¿­ä»£
   - ML æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–

2. **é«˜çº§åŠŸèƒ½**
   - é¢„æµ‹æ€§ç»´æŠ¤å»ºè®®
   - èƒ½è€—ä¼˜åŒ–å»ºè®®
   - è®¾å¤‡ç”Ÿå‘½å‘¨æœŸç®¡ç†

### ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… **ç«‹å³**: å‡†å¤‡ POC ç¯å¢ƒå’Œæµ‹è¯•æ•°æ®
2. âœ… **æœ¬å‘¨**: æ­å»ºå•æœºæµ‹è¯•ç¯å¢ƒ
3. âœ… **ä¸‹å‘¨**: å¼€å‘è½¬æ¢æœåŠ¡åŸå‹
4. âœ… **2å‘¨å†…**: å®Œæˆç«¯åˆ°ç«¯æµ‹è¯•

---

**æœ¬æ–¹æ¡ˆå·²ç»è¿‡å……åˆ†ç ”ç©¶,æŠ€æœ¯è·¯çº¿æ¸…æ™°å¯è¡Œ,å»ºè®®å°½å¿«å¯åŠ¨ POC éªŒè¯ã€‚**
