# Redpanda Connect äºŒè¿›åˆ¶æ•°æ®å¤„ç†åˆ†æ

## æ¦‚è¿°

åœ°é“ç©ºè°ƒæ•°æ®é¡¹ç›®çš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯å¤„ç†åŒ…å«100å¤šä¸ªå­—æ®µçš„äºŒè¿›åˆ¶æ ¼å¼æ•°æ®ã€‚æœ¬æ–‡æ¡£åˆ†æ Redpanda Connect å¤„ç†æ­¤ç±»äºŒè¿›åˆ¶æ•°æ®çš„èƒ½åŠ›å’Œæ–¹æ¡ˆã€‚

## äºŒè¿›åˆ¶æ•°æ®å¤„ç†èƒ½åŠ›

### 1. **åŸç”ŸäºŒè¿›åˆ¶å¤„ç†æ”¯æŒ**

Redpanda Connect æä¾›ä»¥ä¸‹äºŒè¿›åˆ¶æ•°æ®å¤„ç†èƒ½åŠ›:

#### Bloblang å‡½æ•°å’Œæ–¹æ³•

**å†…å®¹å¤„ç†**:
- `content()`: è·å–æ¶ˆæ¯çš„åŸå§‹å­—èŠ‚å†…å®¹
- `bytes()`: å°†å€¼è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
- `string()`: å°†å­—èŠ‚è½¬æ¢ä¸ºå­—ç¬¦ä¸²

**ç¼–ç /è§£ç **:
- `.encode("hex")`: åå…­è¿›åˆ¶ç¼–ç 
- `.decode("hex")`: åå…­è¿›åˆ¶è§£ç 
- `.encode("base64")`: Base64 ç¼–ç 
- `.decode("base64")`: Base64 è§£ç 
- `.encode("ascii")`: ASCII ç¼–ç 
- `.decode("ascii")`: ASCII è§£ç 

**ä½æ“ä½œ**:
- å­—èŠ‚åˆ‡ç‰‡: `this.bytes().slice(0, 4)`
- å­—èŠ‚æ‹¼æ¥: `this.bytes().append(other)`

### 2. **ç»“æ„åŒ–æ•°æ®æ ¼å¼æ”¯æŒ**

#### Schema Registry é›†æˆ

```yaml
pipeline:
  processors:
    - schema_registry_decode:
        url: http://schema-registry:8081
        # è‡ªåŠ¨ä» Kafka æ¶ˆæ¯å¤´è¯»å– schema ID
        # ä½¿ç”¨å¯¹åº”çš„ schema è§£ç äºŒè¿›åˆ¶æ•°æ®
    
    - mapping: |
        # è§£ç åçš„æ•°æ®å·²ç»æ˜¯ JSON æ ¼å¼
        # å¯ä»¥ç›´æ¥è¿›è¡Œå­—æ®µæ˜ å°„
        root.temperature = this.temperature
        root.pressure = this.pressure
```

#### Avro æ ¼å¼å¤„ç†

```yaml
pipeline:
  processors:
    - avro:
        operator: from_json
        encoding: binary
        schema: |
          {
            "type": "record",
            "name": "HVACData",
            "fields": [
              {"name": "temperature", "type": "float"},
              {"name": "pressure", "type": "float"}
            ]
          }
```

#### Protobuf æ ¼å¼å¤„ç†

```yaml
pipeline:
  processors:
    - protobuf:
        operator: from_json
        message: ".HVACData"
        import_paths: ["/schemas"]
```

### 3. **è‡ªå®šä¹‰äºŒè¿›åˆ¶è§£ææ–¹æ¡ˆ**

å¯¹äºè‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼,æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆ:

#### æ–¹æ¡ˆ A: Bloblang ç›´æ¥è§£æ (ç®€å•æ ¼å¼)

é€‚ç”¨äºç»“æ„ç®€å•ã€å›ºå®šé•¿åº¦çš„äºŒè¿›åˆ¶æ ¼å¼:

```yaml
pipeline:
  processors:
    - mapping: |
        # å‡è®¾å‰4å­—èŠ‚æ˜¯æ—¶é—´æˆ³ (uint32)
        let timestamp_bytes = content().slice(0, 4)
        
        # æ¥ä¸‹æ¥4å­—èŠ‚æ˜¯æ¸©åº¦ (float32)
        let temp_bytes = content().slice(4, 8)
        
        # æ³¨æ„: Bloblang å¯¹å¤æ‚äºŒè¿›åˆ¶è§£ææ”¯æŒæœ‰é™
        # é€‚åˆç®€å•çš„å­—èŠ‚åˆ‡ç‰‡å’ŒåŸºç¡€ç±»å‹è½¬æ¢
        root.raw_timestamp = $timestamp_bytes.encode("hex")
        root.raw_temperature = $temp_bytes.encode("hex")
```

> **é™åˆ¶**: Bloblang ä¸ç›´æ¥æ”¯æŒå¤æ‚çš„äºŒè¿›åˆ¶ç±»å‹è½¬æ¢(å¦‚ little-endian float32),éœ€è¦é¢å¤–å¤„ç†ã€‚

#### æ–¹æ¡ˆ B: é¢„å¤„ç† + Schema Registry (æ¨è)

**æ­¥éª¤ 1**: åœ¨æ•°æ®ç”Ÿäº§ç«¯,å°†è‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ (Avro/Protobuf)

**æ­¥éª¤ 2**: ä½¿ç”¨ Schema Registry ç®¡ç†æ•°æ®æ¨¡å¼

**æ­¥éª¤ 3**: Redpanda Connect ä½¿ç”¨ schema_registry_decode è‡ªåŠ¨è§£æ

```mermaid
graph LR
    A[äºŒè¿›åˆ¶æ•°æ®æº] --> B[è½¬æ¢æœåŠ¡<br/>Binary â†’ Avro]
    B --> C[Kafka/Redpanda<br/>with Schema Registry]
    C --> D[Redpanda Connect<br/>schema_registry_decode]
    D --> E[TimescaleDB]
```

#### æ–¹æ¡ˆ C: è‡ªå®šä¹‰ Go æ’ä»¶ (æœ€çµæ´»)

å¯¹äºéå¸¸å¤æ‚çš„äºŒè¿›åˆ¶æ ¼å¼:

```go
// ç¼–å†™è‡ªå®šä¹‰ processor æ’ä»¶
package main

import (
    "github.com/redpanda-data/connect/v4/public/service"
    "encoding/binary"
)

func parseHVACBinary(msg *service.Message) (*service.Message, error) {
    data, err := msg.AsBytes()
    if err != nil {
        return nil, err
    }
    
    // è‡ªå®šä¹‰è§£æé€»è¾‘
    timestamp := binary.LittleEndian.Uint32(data[0:4])
    temperature := binary.LittleEndian.Float32(data[4:8])
    // ... è§£æå…¶ä½™100+å­—æ®µ
    
    // æ„å»º JSON è¾“å‡º
    result := map[string]interface{}{
        "timestamp": timestamp,
        "temperature": temperature,
        // ...
    }
    
    return service.NewMessage(result), nil
}
```

#### æ–¹æ¡ˆ D: WASM æ•°æ®è½¬æ¢

ä½¿ç”¨ WebAssembly æ¨¡å—è¿›è¡Œè‡ªå®šä¹‰è½¬æ¢:

```yaml
pipeline:
  processors:
    - wasm:
        module: ./parsers/hvac_parser.wasm
        function: parse_binary_data
```

## åœ°é“ç©ºè°ƒåœºæ™¯çš„æ¨èæ–¹æ¡ˆ

### åœºæ™¯åˆ†æ

- **æ•°æ®ç‰¹ç‚¹**: 100+ å­—æ®µçš„å¤æ‚äºŒè¿›åˆ¶æ ¼å¼
- **æ•°æ®æº**: æ±‡èšåˆ° Redpanda
- **ç›®æ ‡**: å­˜å‚¨åˆ° TimescaleDB

### æ¨èæ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®é‡‡é›†å±‚"
        A[ç©ºè°ƒè®¾å¤‡] --> B[è¾¹ç¼˜é‡‡é›†å™¨<br/>å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶]
    end
    
    subgraph "æ•°æ®è½¬æ¢å±‚"
        B --> C[è½¬æ¢æœåŠ¡<br/>Binary â†’ Avro/JSON]
        C --> D[Redpanda<br/>with Schema Registry]
    end
    
    subgraph "æ•°æ®å¤„ç†å±‚"
        D --> E[Redpanda Connect<br/>è§£æ + æ˜ å°„ + è®¡ç®—]
        E --> E1[å®æ—¶æ•…éšœæ£€æµ‹]
        E --> E2[æ•°æ®æ¸…æ´—]
        E --> E3[ç‰¹å¾æå–]
    end
    
    subgraph "å­˜å‚¨å±‚"
        E --> F[TimescaleDB<br/>æ—¶åºæ•°æ®å­˜å‚¨]
    end
    
    subgraph "åˆ†æå±‚"
        F --> G[æ•°æ®å±•ç¤º<br/>Grafana/Dashboard]
        F --> H[æ•…éšœé¢„æµ‹æ¨¡å‹<br/>ML Pipeline]
    end
```

### å…·ä½“å®æ–½æ–¹æ¡ˆ

#### é€‰é¡¹ 1: è½¬æ¢æœåŠ¡ + Avro (æ¨è â­)

**ä¼˜ç‚¹**:
- æ•°æ®æ ¼å¼æ ‡å‡†åŒ–
- Schema Registry æä¾›schemaç‰ˆæœ¬ç®¡ç†
- Redpanda Connect åŸç”Ÿæ”¯æŒ,é…ç½®ç®€å•
- æ˜“äºç»´æŠ¤å’Œæ‰©å±•

**å®æ–½æ­¥éª¤**:

1. **å®šä¹‰ Avro Schema**:

```json
{
  "type": "record",
  "name": "MetroHVACData",
  "namespace": "com.metro.hvac",
  "fields": [
    {"name": "device_id", "type": "string"},
    {"name": "timestamp", "type": "long"},
    {"name": "car_number", "type": "int"},
    {"name": "temp_supply_air", "type": "float"},
    {"name": "temp_return_air", "type": "float"},
    {"name": "pressure_compressor", "type": "float"},
    {"name": "current_compressor", "type": "float"},
    {"name": "voltage_input", "type": "float"},
    // ... å…¶ä½™90+å­—æ®µ
    {"name": "fault_code", "type": ["null", "int"], "default": null}
  ]
}
```

2. **è½¬æ¢æœåŠ¡** (Python/Go/Java):

```python
# ä¼ªä»£ç ç¤ºä¾‹
import struct
from confluent_kafka import Producer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroSerializer

def parse_binary_file(binary_data):
    # è§£æäºŒè¿›åˆ¶æ•°æ®
    offset = 0
    device_id = binary_data[offset:offset+16].decode('utf-8')
    offset += 16
    
    timestamp, = struct.unpack('<Q', binary_data[offset:offset+8])
    offset += 8
    
    car_number, = struct.unpack('<I', binary_data[offset:offset+4])
    offset += 4
    
    # ... è§£ææ‰€æœ‰å­—æ®µ
    
    return {
        'device_id': device_id,
        'timestamp': timestamp,
        'car_number': car_number,
        # ...
    }

# å‘é€åˆ° Redpanda
def send_to_redpanda(data):
    avro_serializer = AvroSerializer(schema_registry_client, schema_str)
    producer.produce(
        topic='hvac-data',
        value=avro_serializer(data, SerializationContext('hvac-data', MessageField.VALUE))
    )
```

3. **Redpanda Connect é…ç½®**:

```yaml
input:
  kafka:
    addresses: ["redpanda:9092"]
    topics: ["hvac-data"]
    consumer_group: "hvac-processor"

pipeline:
  processors:
    # è‡ªåŠ¨è§£ç  Avro
    - schema_registry_decode:
        url: http://schema-registry:8081
    
    # æ•°æ®è½¬æ¢å’Œç‰¹å¾æå–
    - mapping: |
        # ä¿ç•™åŸå§‹æ•°æ®
        root = this
        
        # è®¡ç®—æ´¾ç”Ÿå­—æ®µ
        root.temp_diff = this.temp_supply_air - this.temp_return_air
        root.power = this.voltage_input * this.current_compressor
        
        # æ·»åŠ å¤„ç†æ—¶é—´æˆ³
        root.processed_at = now()
        
        # æ•°æ®éªŒè¯
        root.is_valid = this.temp_supply_air > -50 && this.temp_supply_air < 100
    
    # æ•…éšœæ£€æµ‹é€»è¾‘
    - mapping: |
        # ç®€å•çš„è§„åˆ™å¼•æ“
        let high_temp = this.temp_supply_air > 35
        let high_pressure = this.pressure_compressor > 2000
        let high_current = this.current_compressor > 50
        
        root = this
        root.alert_level = if $high_temp && $high_pressure && $high_current {
          "critical"
        } else if $high_temp || $high_pressure {
          "warning"
        } else {
          "normal"
        }
        
        root.needs_maintenance = $high_current

output:
  sql_insert:
    driver: postgres
    dsn: "postgres://user:password@timescaledb:5432/metro_hvac?sslmode=disable"
    table: "hvac_measurements"
    columns:
      - device_id
      - timestamp
      - car_number
      - temp_supply_air
      - temp_return_air
      - pressure_compressor
      - current_compressor
      - voltage_input
      - temp_diff
      - power
      - alert_level
      - needs_maintenance
      - processed_at
    args_mapping: |
      root = [
        this.device_id,
        this.timestamp,
        this.car_number,
        this.temp_supply_air,
        this.temp_return_air,
        this.pressure_compressor,
        this.current_compressor,
        this.voltage_input,
        this.temp_diff,
        this.power,
        this.alert_level,
        this.needs_maintenance,
        this.processed_at
      ]
```

#### é€‰é¡¹ 2: è‡ªå®šä¹‰ Go æ’ä»¶

å¦‚æœä¸æƒ³å¼•å…¥è½¬æ¢æœåŠ¡,ç›´æ¥åœ¨ Redpanda Connect ä¸­å¤„ç†:

**ä¼˜ç‚¹**:
- å‡å°‘ä¸€ä¸ªç»„ä»¶
- æ›´å¥½çš„æ€§èƒ½

**ç¼ºç‚¹**:
- éœ€è¦ç¼–å†™å’Œç»´æŠ¤ Go ä»£ç 
- å‡çº§è¾ƒä¸ºå¤æ‚

#### é€‰é¡¹ 3: JSON æ ¼å¼ (å¦‚æœæ€§èƒ½å¯æ¥å—)

æœ€ç®€å•çš„æ–¹æ¡ˆ:è½¬æ¢æœåŠ¡ç›´æ¥ç”Ÿæˆ JSON:

**ä¼˜ç‚¹**:
- æœ€ç®€å•,æ— éœ€ Schema Registry
- æ˜“äºè°ƒè¯•

**ç¼ºç‚¹**:
- JSON ä½“ç§¯è¾ƒå¤§
- ç¼ºå°‘ schema éªŒè¯

## æ€§èƒ½è€ƒè™‘

### ååé‡è¯„ä¼°

- **Avro æ ¼å¼**: æ¯” JSON å° 30-50%
- **Redpanda Connect**: å•å®ä¾‹å¯å¤„ç† 10,000+ msg/s
- **æ‰¹é‡å†™å…¥**: æå‡æ•°æ®åº“å†™å…¥æ€§èƒ½

### æ‰¹å¤„ç†é…ç½®

```yaml
output:
  sql_insert:
    # ... å…¶ä»–é…ç½®
    batching:
      count: 100       # 100æ¡æ¶ˆæ¯æ‰¹é‡å†™å…¥
      period: 1s       # æˆ–æ¯ç§’å†™å…¥ä¸€æ¬¡
      byte_size": 10MB # æˆ–è¾¾åˆ°10MB
```

## æ€»ç»“

å¯¹äºåœ°é“ç©ºè°ƒé¡¹ç›®çš„100+å­—æ®µäºŒè¿›åˆ¶æ•°æ®:

âœ… **æ¨èæ–¹æ¡ˆ**: è½¬æ¢æœåŠ¡ + Avro + Schema Registry + Redpanda Connect
- æ¶æ„æ¸…æ™°
- æ˜“äºç»´æŠ¤
- æ€§èƒ½ä¼˜ç§€
- æœªæ¥å¯æ‰©å±•

ğŸ”„ **æ›¿ä»£æ–¹æ¡ˆ**: è‡ªå®šä¹‰ Go æ’ä»¶ (å¦‚æœå›¢é˜Ÿæœ‰ Go å¼€å‘èƒ½åŠ›)

âŒ **ä¸æ¨è**: çº¯ Bloblang è§£æå¤æ‚äºŒè¿›åˆ¶æ ¼å¼ (åŠŸèƒ½å—é™)
